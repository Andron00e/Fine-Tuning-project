# Fine-Tuning-project


  Here is my poject concerning fine-tuning of ML models. It consists of several parts mentioned below:
  * fine-tuning [openlm-research/open_llama_3b model](https://huggingface.co/openlm-research/open_llama_3b) using Low-Rank Adaptation technique (LoRA) on [OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca) Q&A dataset 
  *

## Llama-LoRA-Orca
You can see some details in my hf repo [Open-Llama-3B-LoRA-OpenOrca](https://huggingface.co/Andron00e/Open-Llama-3B-LoRA-OpenOrca)


## Citation
```bibtex
@software{openlm2023openllama,
  author = {Geng, Xinyang and Liu, Hao},
  title = {OpenLLaMA: An Open Reproduction of LLaMA},
  month = May,
  year = 2023,
  url = {https://github.com/openlm-research/open_llama}
}
```
